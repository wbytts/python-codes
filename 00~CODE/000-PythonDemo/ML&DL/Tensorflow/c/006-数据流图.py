'''
TensorFlow将数据流图明确地定义为：用节点和有向边描述数学运算的有向无环图。

节点：
    前向图中的节点：
        数学函数或表达式
        占位符(placeholder)。用来描述输入、输出数据的形状、类型等，可以理解为数据流入流出的接口
    后向图中的节点：
        存储模型参数的变量(variable)，它们会随着训练的进行而变化

有向边：数据流图中的有向边用于定义操作之间的关系，它们分为两类：
    一类用来传输数据，绝大部分流动着张量的边都是此类，在上图中用实线表示，简称数据边，
    另一类用来定义控制依赖，通过设定节点的前置依赖决定相关节点的执行顺序，在上图中用虚线表示，简称控制边。

当用户使用TensorFlow执行指定数据流图时，其过程可以简述为以下4个步骤：
    1. 以节点名称作为关键字、入度作为值，创建一张散列表，并将此数据流图上的所有节点数放入散列表中。
    2. 为此数据流图创建一个可执行节点队列，将散列表入度为0的节点加入到该队列，并从散列表中删除这些节点。
    3. 依次执行该队列中的每一个节点，执行成功后将此节点输出指向的节点的入度值减1，更新散列表中对应节点的入度值。
    4。 重复步骤（2）和步骤（3），指导可执行节点队列变为空。


TensorFlow数据流图本身是一个有向无环图，程序结果的正确性依赖于图上节点的执行顺序。
通过这套数据流图执行机制，TensorFlow能够支持复杂、多样化的算法模型。

会话：
TensorFlow数据流图描述了机器学习模型的拓扑结构和所需的训练数据的属性，
但是我们知道， 数据流图只是一个“壳”，只有向“壳”里填入了数据，并执行了相应计算操作后，才能获得最终结果。
TensorFlow会话则为上述的操作提供了运行环境，会话通过提供和切分数据流图、调度并执行操作节点，将抽象的计算拓扑转化为设备上的执行流，从而帮助用户完成计算任务。
我们需要记住一点，TensorFlow的所有实际性操作都要在会话中进行。

Session类用于运行会话的方法是run，
    run方法的参数：
        fetches：待求解的张量或操作
        feed_dict：数据填充字典
    对于没有数据依赖的张量，调用Session.run方法时无需指定数据字典
    对于存在数据依赖的张量，调用Session.run方法时，则需要指定数据填充字典
'''
'''
损失函数就是评估待定模型参数和特定输入时，表达模型输出的推理值与真实值之间不一致程度的函数
常见的损失函数有平方损失函数、交叉熵损失函数和指数损失函数

平方损失函数：loss = (y-yy)^2
交叉熵损失函数：loss = y*log(yy)
指数损失函数：loss = exp(-yy*y)

损害函数是一个非负实值函数，值越小说明模型对训练集拟合得越好，
然而，如果过度追求训练数据上的低损失值，就会遇到过拟合问题，因为训练数据并不能完全代表真实场景的数据分布。
有了评价模型拟合程度的标准的之后，我们就有了具体的训练目标—— 在不影响模型泛化能力的前提下， 找到最优的模型参数使得在训练数据集上训练误差最小。

如何找到最优的参数呢？
这个时候，优化算法就派上用场了。求解最优化问题的算法称为优化算法，它们通常采用迭代方式实现：
首先设定一个初始的可行解，
然后基于特定的函数反复重新计算可行解，
直到找到一个最优解或达到预设的收敛条件。
不同的优化算法采用的迭代策略各有不同，常见的有随机梯度下降算法、牛顿法、Adam优化算法，我们在此不对具体算法的数学原理做详细探究

在TensorFlow中，这些优化算法都被编写成为了一个个的模块，叫做优化器，我们可以直接调用
'''
{'dateCreated': <DateTime '20200113T21:50:00' at 0x1a4f29eae88>, 'description': "摘自：https://www.captainbed.net/2018/11/18/whatisnn/\n\n# 神经网络\n\n人工神经网络是受到人类大脑结构的启发而创造出来的，在我们的大脑中，有数十亿个称为神经元的细胞，它们连接成了一个神经网络。\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113214818649-2146549403.png)\n\n人工神经网络正是模仿了上面的网络结构。下面是一个人工神经网络的构造图。每一个圆代表着一个神经元，他们连接起来构成了一个网络。\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113214832629-548961265.png)\n\n人类大脑神经元细胞的树突接收来自外部的多个强度不同的刺激，并在神经元细胞体内进行处理，然后将其转化为一个输出结果。如下图所示。\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113214857025-167156878.png)\n\n人工神经元也有相似的工作原理。如下图所示。\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113214907455-305052727.png)\n\n上面的x是神经元的输入，相当于树突接收的多个外部刺激。w是每个输入对应的权重，它影响着每个输入x的刺激强度。\n\n大脑的结构越简单，那么智商就越低。单细胞生物是智商最低的了。人工神经网络也是一样的，网络越复杂它就越强大，所以我们需要深度神经网络。这里的深度是指层数多，层数越多那么构造的神经网络就越复杂。\n\n训练深度神经网络的过程就叫做深度学习。\n\n网络构建好了后，我们只需要负责不停地将训练数据输入到神经网络中，它内部就会自己不停地发生变化不停地学习。\n打比方说我们想要训练一个深度神经网络来识别猫。我们只需要不停地将猫的图片输入到神经网络中去。训练成功后，我们任意拿来一张新的图片，它都能判断出里面是否有猫。但我们并不知道他的分析过程是怎样的，它是如何判断里面是否有猫的。就像当我们教小孩子认识猫时，我们拿来一些白猫，告诉他这是猫，拿来一些黑猫，告诉他这也是猫，他脑子里会自己不停地学习猫的特征。最后我们拿来一些花猫，问他，他会告诉你这也是猫。但他是怎么知道的？他脑子里的分析过程是怎么样的？我们无从知道~~\n\n# 如何输入数据\n\n例如：如果要输入一张图像，计算机存储图像，要存储三个独立的矩阵，分别于红色、绿色和蓝色对应，矩阵里的数值就对应于图像的红绿蓝强度值。一般来说，为了方便处理，会将三个矩阵转换成一个向量x。\n\n在人工智能领域，每一个输入到神经网络的数据都被叫做一个特征，这个用来表示的向量也被叫做特征向量。\n\n神经网络接收这个特征向量x作为输入，并进行预测，然后给出相应的结果。\n\n对于不同的应用，需要识别的对象不同，但是它们在计算机中都有对应的数字表示形式，通常我们会把它们转化成一个特征向量，然后将其输入到神经网络中。\n\n# 如何预测\n\n基本神经网络的预测基于一个简单的公式：`z = dot(w, x) + b`\n\n`x` 代表输入的特征向量（如果有三个特征，那么x就可以用 `(x1, x2, x3)` 表示）\n`w` 代表权重，它对应于每个输入特征，代表了每个特征的重要程度。\n`b` 代表阈值，用来影响预测结果\n`z` 就是预测结果\n`dot` 表示将w和x进行向量相乘\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113233526004-1383781447.png)\n\n# 激活函数\n\n在神经网络中，我们不能直接用逻辑回归。必须要在逻辑回归外面再套上一个函数。这个函数称为激活函数。\n\n最简单常用的一种叫做 sigmoid 的激活函数：\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113233812432-912372088.png)\n\n它的用途：把 `z` 映射到 `[0,1]` 之间，从而便于神经网络去进行计算\n\n# 学习\n\n神经网络是如何验证自己预测的结果是否准确呢？\n\n只有知道自己预测的结果是否准确，才能够对自身进行调整，让结果越来越准确，这就是学习的过程。\n\n验证学习成果，判断预测结果是否准确，一种方法就是 损失函数（loss function）\n比如这个例子：我们使用预测结果与实际结果的差的平方乘以二分之一。\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113234223731-1373012027.png)\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113234233247-1709762899.png)\n\n但是实际上我们使用的损失函数是：![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200113234437958-1775331814.png)\n\n损失函数的计算结果越大，说明成本越大，即预测越不准确\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119032330921-1911754848.png)\n\n\n# 梯度下降\n\n预测结果是否准确是由 `w` 和 `b` 决定的，所以神经网络学习的目的就是要找到合适的 `w` 和 `b`。\n\n通过一个叫做梯度下降的算法可以达到这个目的。梯度下降算法会一步步地改变w和b的值，新的w和b的值会使损失函数的输出结果更小，即一步步让预测更加准确。\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119032447702-2110180632.png)\n\n在上面提到的逻辑回归算法里，输入x和实际结果y都是固定的，损失函数其实是一个关于w和b的函数（w和b是变量）\n\n学习 或者说 训练神经网络，其实就是找到一组 w和b ，使这个损失函数最小，即使结果更精准\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119032653927-1058826782.png)\n\n损失函数 J 的形状是一个漏斗状。我们训练的目的就是找到在漏斗底部的一组 w和b\n\n这种漏斗状的函数被称为 `凸函数 `，选择 J 就是因为它是一个凸函数\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119032813797-242825919.png)\n\n如上图，梯度下降算法会一步步地更新 w和b，使损失函数一步步地变小，最终找到最小值或者接近最小值的地方\n\n![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119032936697-1660475334.png)\n\n梯度下降更新参数的原理：\n假设损失函数J只有一个参数w，并且假设w只是一个实数，则可以通过公式 `w' = w - r * dw` 来改变w的值。\n梯度下降算法就是重复执行上面的公式来不停地更新w的值。新的w的值等于旧的w减去学习率r与偏导数dw的乘积。\n\nr：学习步进、学习率（learning rate），r是我们用来控制w的变化步进的参数\ndw：参数w关于损失函数J的偏导数\n\n神经网络就是通过梯度下降算法来一步步改变w和b的值，使损失函数越来越小，使预测越来越精准", 'title': '神经网络入门：什么是神经网络？', 'categories': ['[随笔分类]AI~', '[随笔分类]AI~深度学习'], 'enclosure': {'length': 0}, 'link': 'https://www.cnblogs.com/wbyixx/p/12189535.html', 'permalink': 'https://www.cnblogs.com/wbyixx/p/12189535.html', 'postid': '12189535', 'source': {}, 'userid': '-2'}
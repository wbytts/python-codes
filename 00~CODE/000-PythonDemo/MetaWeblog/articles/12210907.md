在实际使用的时候，神经网络是很复杂的，要借助计算图才能使其条理清晰，让复杂的事情变的直观便于研究。

神经网络的计算是有一个前向传播以及一个反向传播构成的。
先通过前向传播计算出预测结果以及损失；然后再通过反向传播计算出损失函数关于每一个参数 w,b 的偏导数，并对这些参数进行梯度下降
然后用新的参数进行新一轮的前向传播计算，这样来回不停地进行前向传播反向传播计算来训练（更新）参数使损失函数越来越小，使预测越来越准确

通过计算图可以把上面的计算过程非常直观地展示出来：

`J(a, b, c) = 3(a + bc)`
- 若第一步用 U 来表示，则 `U = bc`
- 第二步用 V 来表示，则 `V = a + U`
- 最后是 `J = 3V`

用图像表示如下：
![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119034442007-39937135.png)

反向传播用于计算函数 J 关于各个参数的偏导数，然后对其进行梯度下降：
![](https://img2018.cnblogs.com/blog/1446249/202001/1446249-20200119034703218-2017775265.png)
